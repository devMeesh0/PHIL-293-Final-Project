{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "import joblib  \n",
    "\n",
    "# Load the pre-trained logistic regression model and scaler\n",
    "model = joblib.load('logreg_model.pkl')  # Load saved model for predictions\n",
    "\n",
    "# Load the new dataset (Legal Occupations dataset)\n",
    "df = pd.read_csv(\"Community_and_Social_Service_Occupations.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(df.head())\n",
    "\n",
    "# Convert 'Automatability' into binary labels (0 and 1) based on threshold of 0.5\n",
    "df['Automatibility_Label'] = (df['Automatability'] >= 0.5).astype(int)\n",
    "\n",
    "# Drop the original 'Automatability' column as it's no longer needed\n",
    "df.drop(columns=['Automatability'], inplace=True)\n",
    "\n",
    "# Convert 'Task Type' to binary values (0 for Core, 1 for Supplemental)\n",
    "df['Task Type'] = df['Task Type'] - 1  # 1 becomes 0 (Core), 2 becomes 1 (Supplemental)\n",
    "\n",
    "# Encode 'Scale Name' categorical variable into numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Scale Name'] = label_encoder.fit_transform(df['Scale Name'])\n",
    "\n",
    "# Remove unnecessary columns like 'O*NET-SOC Code', 'Task ID', etc.\n",
    "columns_to_drop = [\"O*NET-SOC Code\", \"Task ID\", \"Task_x\", \"Title\", \"Category\"]\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Handle missing values by replacing them with the mean of the respective column\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Define feature matrix (X) and target variable (y)\n",
    "X = df.drop(columns=[\"Automatibility_Label\"])\n",
    "y = df[\"Automatibility_Label\"]\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Use the pre-trained model to make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for ROC curve\n",
    "\n",
    "# Evaluate the model's performance using classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate ROC curve and AUC for model evaluation\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve with AUC score\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")  # Diagonal line for random classifier\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Print AUC score for the model\n",
    "print(f\"AUC Score: {roc_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
